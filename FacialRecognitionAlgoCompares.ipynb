{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb0ee7a8-4fb3-445c-9f70-9fcd4b57683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This code is designed to compare as many facial detection algorithms as possible. The metrics for comparision are:\n",
    "accuracy, total time to process, time to process per image. \n",
    "\n",
    "Links to algorithms, datasets, and other resources used:\n",
    "OpenCV2: https://opencv.org/\n",
    "Facenet-pytorch: https://github.com/timesler/facenet-pytorch\n",
    "Deepface: https://github.com/serengil/deepface\n",
    "InsightFace: https://github.com/deepinsight/insightface\n",
    "dlib: http://dlib.net/\n",
    "Retinaface (python ver.): https://github.com/heewinkim/retinaface and https://github.com/biubug6/Pytorch_Retinaface\n",
    "DSFD: https://github.com/hukkelas/DSFD-Pytorch-Inference\n",
    "Blazeface (mediapipe ver.): https://google.github.io/mediapipe/\n",
    "yoloface: https://pypi.org/project/yoloface/\n",
    "Caltech256 dataset: https://www.kaggle.com/jessicali9530/caltech256\n",
    "FaceForensics++ dataset: https://github.com/ondyari/FaceForensics\n",
    "\n",
    "@author Bryce Gernon\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Stats recorded on an RTX2080Ti GPU, where applicable. \n",
    "Dataset used is 10000 original faces from the FaceForensics++ dataset and 10000 non-face objects from the Caltech 256 dataset.\n",
    "\n",
    "OpenCV cpu (default haar cascade classifier): 68.16%, 204.81s, .010s/image\n",
    "MTCNN (default pretrained): 94.465%, 287.34s, .014s/image\n",
    "DeepFace OpenCV haar: 84.30%, 238.96s, .012s/image\n",
    "DeepFace OpenCV ssd: 96.09%, 227.15s, .011s/image\n",
    "dlib: 98.425%, 4143.69s, .207s/image\n",
    "RetinaFace: 40.145%, 3081.26s, .154s/image\n",
    "DeepFace retinaface: 93.85%, 1716.77s, .086s/image\n",
    "DSFD (pytorch ver.): 94.295%, 693.93s, .035s/image \n",
    "BlazeFace (mediapipe): 96.22%, 144.60s, .007s/image\n",
    "yoloface: 70.45%, 232.68s, .012s/image\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "from argparse import ArgumentParser\n",
    "import dlib\n",
    "import os\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision as tv\n",
    "import torch\n",
    "import inspect\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "import random\n",
    "import deepface\n",
    "from deepface import DeepFace \n",
    "from retinaface import RetinaFace\n",
    "from retinaface.pre_trained_models import get_model\n",
    "import face_detection\n",
    "from face_detection import build_detector\n",
    "import tensorflow\n",
    "import insightface_paddle\n",
    "import logging\n",
    "import easydict\n",
    "import mediapipe as mp\n",
    "from yoloface import face_analysis\n",
    "import pkgutil\n",
    "from mmdet import apis as mmdetstuff\n",
    "\n",
    "backends = ['retinaface', 'opencv' , 'mtcnn']\n",
    "face_detection_models = ['DSFDDetector']\n",
    "PATH1 = \"../../../data/datasets/FaceForensics++/Faces/DeepFakes/val/original\" # This can be any directory containing (possibly nested in folders) jpg images of single faces.\n",
    "PATH2 = \"../../../data/datasets/Caltech256/256_ObjectCategories\" # This can be any directory containing (possibly nested in folders) jpg images of non-face images.\n",
    "NONFACE_NUM = 100\n",
    "FACE_NUM = 100\n",
    "RETINA_QUALITY = \"normal\"\n",
    "\n",
    "def get_nonface():\n",
    "    \"\"\" Uses the directory in PATH2 to obtain and label non-face images. \n",
    "    Data is returned in list format [[boolean isFace, Image.open(image), string path_to_image], ...]\n",
    "    \n",
    "    \"\"\"\n",
    "    database = []\n",
    "    current_num = 0\n",
    "    for directory in os.listdir(PATH2):\n",
    "        for image in os.listdir(PATH2 + \"/\" + directory):\n",
    "            if image.endswith(\"jpg\"):\n",
    "                with Image.open(PATH2 + \"/\" + directory + \"/\" + image) as im:\n",
    "                    database.append([False, im, PATH2 + \"/\" + directory + \"/\" + image])\n",
    "                    current_num += 1\n",
    "                    if (current_num >= NONFACE_NUM):\n",
    "                        print(\"Non-faces stored in database: \" + str(current_num))\n",
    "                        return database\n",
    "\n",
    "def make_dataset(p1, p2):\n",
    "    #  First, get caltech images and load into new list with new labels (False for no face) + existing image data\n",
    "    database = get_nonface()\n",
    "        \n",
    "\n",
    "    # Next, get facial images from FaceForensics++, and load them into previous list with new labels (True for face) + existing image data + path to image\n",
    "\n",
    "    current_num = 0\n",
    "    for directory in os.listdir(PATH1):\n",
    "        for image in os.listdir(PATH1 + \"/\" + directory):\n",
    "            if image.endswith(\"jpg\"):\n",
    "                with Image.open(PATH1 + \"/\" + directory + \"/\" + image) as im:\n",
    "                    database.append([True, im, PATH1 + \"/\" + directory + \"/\" + image])\n",
    "                    current_num += 1\n",
    "                    if (current_num >= FACE_NUM):\n",
    "                        print(\"Faces stored in database: \" + str(current_num))\n",
    "                        return database\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "268305f9-6803-4ce8-8673-d8cf54c7dd1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-faces stored in database: 100\n",
      "Faces stored in database: 100\n",
      "Total dataset length: 200\n",
      "Beginning algorithm comparisons...\n",
      "Creating face analysis...\n",
      "yolov3-tiny_face.weights:: status : file already exists\n",
      "yolov3_tiny_face.cfg:: status : file already exists\n",
      "face_detection.weights:: status : file already exists\n",
      "face_detection.cfg:: status : file already exists\n",
      "Analyzing batches...\n",
      "Algorithm used: Yoloface\n",
      "Time taken: 1.0430898666381836s\n",
      "Time taken per image: 0.005215504169464111s\n",
      "Number correct: 0\n",
      "Accuracy: 0.0%\n",
      "\n",
      "Algorithm used: Opencv default haar cascade classifier\n",
      "Time taken: 0.012259960174560547s\n",
      "Time taken per image: 6.134986877441406e-05s\n",
      "Number correct: 0\n",
      "Accuracy: 0.0%\n",
      "\n",
      "Algorithm used: MTCNN\n",
      "Time taken: 3.266334533691406e-05s\n",
      "Time taken per image: 2.300739288330078e-07s\n",
      "Number correct: 0\n",
      "Accuracy: 0.0%\n",
      "\n",
      "Algorithm used: Dlib\n",
      "Time taken: 0.0025742053985595703s\n",
      "Time taken per image: 1.293182373046875e-05s\n",
      "Number correct: 0\n",
      "Accuracy: 0.0%\n",
      "\n",
      "Algorithm used: Retinaface, quality=normal\n",
      "Time taken: 0.962017297744751s\n",
      "Time taken per image: 0.004810148477554321s\n",
      "Number correct: 0\n",
      "Accuracy: 0.0%\n",
      "\n",
      "Algorithm used: DSFDDetector\n",
      "Time taken: 7.505142688751221s\n",
      "Time taken per image: 0.03752577304840088s\n",
      "Number correct: 154\n",
      "Accuracy: 77.0%\n",
      "\n",
      "Algorithm used: Mediapipe Blazeface\n",
      "Time taken: 1.9324324131011963s\n",
      "Time taken per image: 0.009662208557128906s\n",
      "Number correct: 198\n",
      "Accuracy: 99.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compare(data):    \n",
    "    print(\"Beginning algorithm comparisons...\")    \n",
    "    count = 0\n",
    "    correct = 0\n",
    "    start = time.time()\n",
    "    print(\"Creating face analysis...\")\n",
    "    face = face_analysis()\n",
    "    print(\"Analyzing batches...\")\n",
    "    random.shuffle(data)\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "    #################################################################################################\n",
    "    for batch in data:\n",
    "        img,box,conf=face.face_detection(image_path=batch[2],model='full')\n",
    "        if (batch[0] == True and len(box) == 1) or (batch[0] == False and len(box) == 0):\n",
    "            correct = correct + 1\n",
    "        count = count + 1\n",
    "        if (count % 1000) == 0:\n",
    "            print(\"Processed \" + str(count) + \" images.\")    \n",
    "    print(\"Algorithm used: Yoloface\") \n",
    "    print(\"Time taken: \" + str(time.time() - start) + \"s\")\n",
    "    print(\"Time taken per image: \" + str((time.time()-start)/len(data)) + \"s\")\n",
    "    print(\"Number correct: \" + str(correct))\n",
    "    print(\"Accuracy: \" + str((correct/(len(data)))*100) + \"%\")\n",
    "    print()\n",
    "    #################################################################################################\n",
    "    start = time.time()\n",
    "    correct = 0\n",
    "    haar_cv2 = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    count = 0\n",
    "    for batch in data:\n",
    "        image = cv2.cvtColor(cv2.imread(batch[2]), cv2.COLOR_BGR2RGB)\n",
    "        faces = haar_cv2.detectMultiScale(image)\n",
    "        if (batch[0] == True and len(faces) > 0) or (batch[0] == False and len(faces) == 0):\n",
    "            correct = correct + 1\n",
    "        count = count + 1\n",
    "        if (count % 1000) == 0:\n",
    "            print(\"Processed \" + str(count) + \" images.\")    \n",
    "    print(\"Algorithm used: Opencv default haar cascade classifier\") \n",
    "    print(\"Time taken: \" + str(time.time() - start) + \"s\")\n",
    "    print(\"Time taken per image: \" + str((time.time()-start)/len(data)) + \"s\")\n",
    "    print(\"Number correct: \" + str(correct))\n",
    "    print(\"Accuracy: \" + str((correct/(len(data)))*100) + \"%\")\n",
    "    print()\n",
    "    #################################################################################################\n",
    "    mtcnn = MTCNN(device='cuda', keep_all=True, margin=20).eval()\n",
    "    count = 0\n",
    "    correct = 0\n",
    "    start = time.time()\n",
    "    for batch in data:\n",
    "        faces = mtcnn.detect(cv2.imread(batch[2])[:, :, ::-1])\n",
    "        if faces[0] is not None:\n",
    "            if (batch[0] == True) and (len(faces) == 1):\n",
    "                correct = correct + 1\n",
    "        else:\n",
    "            if (batch[0] == False):\n",
    "                correct = correct + 1\n",
    "        count = count + 1\n",
    "        if (count % 1000) == 0:\n",
    "            print(\"Processed \" + str(count) + \" images.\")\n",
    "    print(\"Algorithm used: MTCNN\") \n",
    "    print(\"Time taken: \" + str(time.time() - start) + \"s\")\n",
    "    print(\"Time taken per image: \" + str((time.time()-start)/len(data)) + \"s\")\n",
    "    print(\"Number correct: \" + str(correct))\n",
    "    print(\"Accuracy: \" + str((correct/(len(data)))*100) + \"%\")\n",
    "    print()\n",
    "    #################################################################################################\n",
    "    DeepFace.env = 'cuda'\n",
    "    DeepFace.device = 'cuda'\n",
    "    for backend in backends:\n",
    "        count = 0\n",
    "        correct = 0\n",
    "        start = time.time()\n",
    "        for batch in data:\n",
    "            faces = DeepFace.detectFace(img_path=batch[2], detector_backend=backend, enforce_detection=False)\n",
    "            if (batch[0] == True and faces[0][0][0] != 0.0) or (batch[0] == False and faces[0][0][0] == 0.0):\n",
    "                correct = correct + 1\n",
    "            count = count + 1\n",
    "            if (count % 1000) == 0:\n",
    "                print(\"Processed \" + str(count) + \" images.\")\n",
    "        print(\"Algorithm used: DeepFace \" + backend) \n",
    "        print(\"Time taken: \" + str(time.time() - start) + \"s\")\n",
    "        print(\"Time taken per image: \" + str((time.time()-start)/len(data)) + \"s\")\n",
    "        print(\"Number correct: \" + str(correct))\n",
    "        print(\"Accuracy: \" + str((correct/(len(data)))*100) + \"%\")\n",
    "        print()\n",
    "    #################################################################################################\n",
    "    count = 0\n",
    "    correct = 0\n",
    "    start = time.time()\n",
    "    cnn_face_detector = dlib.cnn_face_detection_model_v1('mmod_human_face_detector.dat')\n",
    "    for batch in data:\n",
    "        img = dlib.load_rgb_image(batch[2])\n",
    "        faces = cnn_face_detector(img, 1)\n",
    "        if (batch[0] == True and len(faces) == 1) or (batch[0] == False and len(faces) == 0):\n",
    "            correct = correct + 1\n",
    "        count = count + 1\n",
    "        if (count % 1000) == 0:\n",
    "            print(\"Processed \" + str(count) + \" images.\")   \n",
    "    print(\"Algorithm used: Dlib\") \n",
    "    print(\"Time taken: \" + str(time.time() - start) + \"s\")\n",
    "    print(\"Time taken per image: \" + str((time.time()-start)/len(data)) + \"s\")\n",
    "    print(\"Number correct: \" + str(correct))\n",
    "    print(\"Accuracy: \" + str((correct/(len(data)))*100) + \"%\")\n",
    "    print()\n",
    "    #################################################################################################\n",
    "    count = 0\n",
    "    correct = 0\n",
    "    start = time.time()\n",
    "    model = get_model(\"resnet50_2020-07-20\", max_size=2048, device=\"cuda\")\n",
    "    model.eval()\n",
    "    for batch in data:\n",
    "        image = cv2.imread(batch[2])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        faces = model.predict_jsons(image)\n",
    "        if (batch[0] == True and len(faces) == 1 and len(faces[0]['bbox']) != 0) or (batch[0] == False and len(faces[0]['bbox']) == 0):\n",
    "            correct = correct + 1\n",
    "        count = count + 1\n",
    "        if (count % 1000) == 0:\n",
    "            print(\"Processed \" + str(count) + \" images.\")   \n",
    "    print(\"Algorithm used: Retinaface, quality=\" + RETINA_QUALITY) \n",
    "    print(\"Time taken: \" + str(time.time() - start) + \"s\")\n",
    "    print(\"Time taken per image: \" + str((time.time()-start)/len(data)) + \"s\")\n",
    "    print(\"Number correct: \" + str(correct))\n",
    "    print(\"Accuracy: \" + str((correct/(len(data)))*100) + \"%\")\n",
    "    print()\n",
    "    #################################################################################################\n",
    "    count = 0\n",
    "    correct = 0\n",
    "    start = time.time()\n",
    "    for model_type in face_detection_models:\n",
    "        detector = build_detector(model_type, confidence_threshold=.5, nms_iou_threshold=.3, device=\"cuda\")\n",
    "        for batch in data:\n",
    "            image = cv2.imread(batch[2])[:, :, ::-1]\n",
    "            faces = detector.detect(image)\n",
    "            if (batch[0] == True and len(faces) == 1) or (batch[0] == False and len(faces) == 0):\n",
    "                correct = correct + 1\n",
    "            count = count + 1\n",
    "            if (count % 1000) == 0:\n",
    "                print(\"Processed \" + str(count) + \" images.\")\n",
    "    \n",
    "        print(\"Algorithm used: \" + model_type) \n",
    "        print(\"Time taken: \" + str(time.time() - start) + \"s\")\n",
    "        print(\"Time taken per image: \" + str((time.time()-start)/len(data)) + \"s\")\n",
    "        print(\"Number correct: \" + str(correct))\n",
    "        print(\"Accuracy: \" + str((correct/(len(data)))*100) + \"%\")\n",
    "        print()\n",
    "        count = 0\n",
    "        correct = 0\n",
    "        start = time.time()\n",
    "    #################################################################################################\n",
    "    mp_face_detection = mp.solutions.face_detection\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "    with mp_face_detection.FaceDetection(min_detection_confidence=0.67) as face_detection:\n",
    "        for batch in data:\n",
    "            image = cv2.cvtColor(cv2.imread(batch[2]), cv2.COLOR_BGR2RGB)\n",
    "            faces = face_detection.process(image)\n",
    "            if faces.detections is not None:\n",
    "                if (batch[0] == True) and (len(faces.detections) == 1):\n",
    "                    correct = correct + 1\n",
    "            else:\n",
    "                if (batch[0] == False):\n",
    "                    correct = correct + 1   \n",
    "            count = count + 1\n",
    "            if (count % 1000) == 0:\n",
    "                print(\"Processed \" + str(count) + \" images.\")    \n",
    "    print(\"Algorithm used: Mediapipe Blazeface\") \n",
    "    print(\"Time taken: \" + str(time.time() - start) + \"s\")\n",
    "    print(\"Time taken per image: \" + str((time.time()-start)/len(data)) + \"s\")\n",
    "    print(\"Number correct: \" + str(correct))\n",
    "    print(\"Accuracy: \" + str((correct/(len(data)))*100) + \"%\")\n",
    "    print()\n",
    "    #################################################################################################\n",
    "    \n",
    "\n",
    "def main():\n",
    "    dataset = make_dataset(PATH1, PATH2)\n",
    "    print(\"Total dataset length: \" + str(len(dataset)))\n",
    "    compare(dataset)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff79a82-cd9d-4160-8ab2-4a56c5cfa1a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dba642-afa7-44bd-b2db-c771068e89cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
